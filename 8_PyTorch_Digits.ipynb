{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_PyTorch_Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNB7ogddopYqmFoUzkoa6YX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabair/ml-kurs-ss21/blob/master/8_PyTorch_Digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOBUyiZq3d2u"
      },
      "source": [
        "# PyTorch Digits Example\n",
        "This example classifies the digit dataset using a neural net.\n",
        "For more details on the dataset, check [this](https://github.com/pabair/ml-kurs-ss21/blob/master/2_Logistische_Regression_Digits.ipynb) notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhdvnPe4Q-pO"
      },
      "source": [
        "### 0. Preamble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8-YOrlu3w8z"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3DgoJj735Gr",
        "outputId": "e56e337f-c44f-4bc3-c1ae-e532bb999356"
      },
      "source": [
        "if(torch.cuda.is_available()):\n",
        "  processing_chip = \"cuda:0\"\n",
        "  print(f\"{torch.cuda.get_device_name(0)} available\")\n",
        "else:\n",
        "  processing_chip = \"cpu\"\n",
        "  print(\"No GPU available\")\n",
        "\n",
        "device = torch.device(processing_chip)\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU available\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8EgmXccAr9b"
      },
      "source": [
        "### 1. Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZoYUZfQ_TU8"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "data, labels = load_digits(return_X_y = True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfY2iF0WTlWu"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_X, test_X, train_y, test_y = train_test_split(data, labels, test_size=0.2, random_state=0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQqdZZ16AHBe",
        "outputId": "75f7aff9-a647-4010-bafa-8141fc7aa46d"
      },
      "source": [
        "train_X"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  0., ..., 16., 16.,  6.],\n",
              "       [ 0.,  3., 12., ..., 16.,  2.,  0.],\n",
              "       [ 0.,  1., 10., ...,  0.,  0.,  0.],\n",
              "       ...,\n",
              "       [ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
              "       [ 0.,  0.,  4., ...,  0.,  0.,  0.],\n",
              "       [ 0.,  0.,  6., ..., 11.,  0.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OI44o3i-grB"
      },
      "source": [
        "train_x = torch.Tensor(train_X).float().to(device)\n",
        "test_x = torch.Tensor(test_X).float().to(device)\n",
        "train_y =torch.Tensor(train_y).long().to(device)\n",
        "test_y = torch.Tensor(test_y).long().to(device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wcTXnyu7NWK"
      },
      "source": [
        "### 2. Model definition \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W47oZ534E-1"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.hidden1 = nn.Linear(64, 5)\n",
        "    self.hidden2 = nn.Linear(5, 7)  \n",
        "    self.output = nn.Linear(7, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = F.relu(self.hidden1(x))\n",
        "    z = F.relu(self.hidden2(z))\n",
        "    z = self.output(z)  # no softmax. see CrossEntropyLoss() \n",
        "    return z"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJyy5JG_84vs"
      },
      "source": [
        "### 3. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RQHZvvyAFzV",
        "outputId": "85c7caef-49ee-443f-d052-30af1758c4a2"
      },
      "source": [
        "# create network, move it to device and set it to training-mode\n",
        "net = Net().to(device)\n",
        "net.train()\n",
        "\n",
        "# define the parameters for training\n",
        "no_epochs = 5000\n",
        "learning_rate = 0.01\n",
        "loss_func = nn.CrossEntropyLoss()  # applies softmax() internally\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "\n",
        "print(\"\\nStarting training \")\n",
        "\n",
        "train_losses = []\n",
        "for epoch in range(0, no_epochs):\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  output = net(train_x)\n",
        "\n",
        "  loss = loss_func(output, train_y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  train_losses.append(loss.item())\n",
        "  \n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Loss in epoch {epoch} is {loss.item()}\")\n",
        "\n",
        "print(\"Done training \")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training \n",
            "Loss in epoch 0 is 2.483743906021118\n",
            "Loss in epoch 10 is 2.2992963790893555\n",
            "Loss in epoch 20 is 2.2463860511779785\n",
            "Loss in epoch 30 is 2.206214666366577\n",
            "Loss in epoch 40 is 2.1667559146881104\n",
            "Loss in epoch 50 is 2.1252381801605225\n",
            "Loss in epoch 60 is 2.0811972618103027\n",
            "Loss in epoch 70 is 2.03448224067688\n",
            "Loss in epoch 80 is 1.9860403537750244\n",
            "Loss in epoch 90 is 1.9372819662094116\n",
            "Loss in epoch 100 is 1.8889433145523071\n",
            "Loss in epoch 110 is 1.8417812585830688\n",
            "Loss in epoch 120 is 1.7961574792861938\n",
            "Loss in epoch 130 is 1.751318335533142\n",
            "Loss in epoch 140 is 1.7079929113388062\n",
            "Loss in epoch 150 is 1.6661914587020874\n",
            "Loss in epoch 160 is 1.6260013580322266\n",
            "Loss in epoch 170 is 1.5874701738357544\n",
            "Loss in epoch 180 is 1.5508407354354858\n",
            "Loss in epoch 190 is 1.5158514976501465\n",
            "Loss in epoch 200 is 1.482245683670044\n",
            "Loss in epoch 210 is 1.4499739408493042\n",
            "Loss in epoch 220 is 1.4189562797546387\n",
            "Loss in epoch 230 is 1.3894201517105103\n",
            "Loss in epoch 240 is 1.3612138032913208\n",
            "Loss in epoch 250 is 1.3339855670928955\n",
            "Loss in epoch 260 is 1.307679533958435\n",
            "Loss in epoch 270 is 1.2820172309875488\n",
            "Loss in epoch 280 is 1.2571051120758057\n",
            "Loss in epoch 290 is 1.2327852249145508\n",
            "Loss in epoch 300 is 1.2086467742919922\n",
            "Loss in epoch 310 is 1.1847710609436035\n",
            "Loss in epoch 320 is 1.1614954471588135\n",
            "Loss in epoch 330 is 1.1384820938110352\n",
            "Loss in epoch 340 is 1.1158767938613892\n",
            "Loss in epoch 350 is 1.0937647819519043\n",
            "Loss in epoch 360 is 1.07217538356781\n",
            "Loss in epoch 370 is 1.050430178642273\n",
            "Loss in epoch 380 is 1.0282329320907593\n",
            "Loss in epoch 390 is 1.0062288045883179\n",
            "Loss in epoch 400 is 0.9844510555267334\n",
            "Loss in epoch 410 is 0.9627918601036072\n",
            "Loss in epoch 420 is 0.9409788846969604\n",
            "Loss in epoch 430 is 0.9193518757820129\n",
            "Loss in epoch 440 is 0.8981907963752747\n",
            "Loss in epoch 450 is 0.87735915184021\n",
            "Loss in epoch 460 is 0.8568664789199829\n",
            "Loss in epoch 470 is 0.8368003368377686\n",
            "Loss in epoch 480 is 0.8173706531524658\n",
            "Loss in epoch 490 is 0.7988772988319397\n",
            "Loss in epoch 500 is 0.7812323570251465\n",
            "Loss in epoch 510 is 0.7644420266151428\n",
            "Loss in epoch 520 is 0.7483154535293579\n",
            "Loss in epoch 530 is 0.7327653169631958\n",
            "Loss in epoch 540 is 0.7178939580917358\n",
            "Loss in epoch 550 is 0.7037084698677063\n",
            "Loss in epoch 560 is 0.6900222897529602\n",
            "Loss in epoch 570 is 0.6771773099899292\n",
            "Loss in epoch 580 is 0.6649320125579834\n",
            "Loss in epoch 590 is 0.6532344818115234\n",
            "Loss in epoch 600 is 0.6420308351516724\n",
            "Loss in epoch 610 is 0.6313813328742981\n",
            "Loss in epoch 620 is 0.6213043332099915\n",
            "Loss in epoch 630 is 0.6117708086967468\n",
            "Loss in epoch 640 is 0.602624237537384\n",
            "Loss in epoch 650 is 0.5939766764640808\n",
            "Loss in epoch 660 is 0.5858021378517151\n",
            "Loss in epoch 670 is 0.5780697464942932\n",
            "Loss in epoch 680 is 0.5706365704536438\n",
            "Loss in epoch 690 is 0.5635660290718079\n",
            "Loss in epoch 700 is 0.5567636489868164\n",
            "Loss in epoch 710 is 0.5502094626426697\n",
            "Loss in epoch 720 is 0.5438701510429382\n",
            "Loss in epoch 730 is 0.5375605225563049\n",
            "Loss in epoch 740 is 0.5314764976501465\n",
            "Loss in epoch 750 is 0.5256702899932861\n",
            "Loss in epoch 760 is 0.5200309157371521\n",
            "Loss in epoch 770 is 0.5145842432975769\n",
            "Loss in epoch 780 is 0.5094489455223083\n",
            "Loss in epoch 790 is 0.5045340657234192\n",
            "Loss in epoch 800 is 0.4997161030769348\n",
            "Loss in epoch 810 is 0.49505525827407837\n",
            "Loss in epoch 820 is 0.4904794991016388\n",
            "Loss in epoch 830 is 0.48602864146232605\n",
            "Loss in epoch 840 is 0.4816683530807495\n",
            "Loss in epoch 850 is 0.47743889689445496\n",
            "Loss in epoch 860 is 0.4733869433403015\n",
            "Loss in epoch 870 is 0.469416081905365\n",
            "Loss in epoch 880 is 0.4655381143093109\n",
            "Loss in epoch 890 is 0.46177032589912415\n",
            "Loss in epoch 900 is 0.4580739438533783\n",
            "Loss in epoch 910 is 0.45451629161834717\n",
            "Loss in epoch 920 is 0.45112669467926025\n",
            "Loss in epoch 930 is 0.44781315326690674\n",
            "Loss in epoch 940 is 0.44455987215042114\n",
            "Loss in epoch 950 is 0.44139188528060913\n",
            "Loss in epoch 960 is 0.4382745921611786\n",
            "Loss in epoch 970 is 0.43518492579460144\n",
            "Loss in epoch 980 is 0.4321907162666321\n",
            "Loss in epoch 990 is 0.4292970895767212\n",
            "Loss in epoch 1000 is 0.4264219403266907\n",
            "Loss in epoch 1010 is 0.4235873818397522\n",
            "Loss in epoch 1020 is 0.42081135511398315\n",
            "Loss in epoch 1030 is 0.418082594871521\n",
            "Loss in epoch 1040 is 0.4154171347618103\n",
            "Loss in epoch 1050 is 0.41282299160957336\n",
            "Loss in epoch 1060 is 0.41027623414993286\n",
            "Loss in epoch 1070 is 0.4077657163143158\n",
            "Loss in epoch 1080 is 0.40528604388237\n",
            "Loss in epoch 1090 is 0.4028582274913788\n",
            "Loss in epoch 1100 is 0.40047532320022583\n",
            "Loss in epoch 1110 is 0.3981267213821411\n",
            "Loss in epoch 1120 is 0.39581507444381714\n",
            "Loss in epoch 1130 is 0.39354172348976135\n",
            "Loss in epoch 1140 is 0.39129549264907837\n",
            "Loss in epoch 1150 is 0.38907843828201294\n",
            "Loss in epoch 1160 is 0.3868938982486725\n",
            "Loss in epoch 1170 is 0.38474366068840027\n",
            "Loss in epoch 1180 is 0.38262420892715454\n",
            "Loss in epoch 1190 is 0.38053014874458313\n",
            "Loss in epoch 1200 is 0.37842196226119995\n",
            "Loss in epoch 1210 is 0.376343697309494\n",
            "Loss in epoch 1220 is 0.3742869794368744\n",
            "Loss in epoch 1230 is 0.37227046489715576\n",
            "Loss in epoch 1240 is 0.37029320001602173\n",
            "Loss in epoch 1250 is 0.36833250522613525\n",
            "Loss in epoch 1260 is 0.36637818813323975\n",
            "Loss in epoch 1270 is 0.36440324783325195\n",
            "Loss in epoch 1280 is 0.36246469616889954\n",
            "Loss in epoch 1290 is 0.36054694652557373\n",
            "Loss in epoch 1300 is 0.3586665689945221\n",
            "Loss in epoch 1310 is 0.35681843757629395\n",
            "Loss in epoch 1320 is 0.35497966408729553\n",
            "Loss in epoch 1330 is 0.3531534969806671\n",
            "Loss in epoch 1340 is 0.3513453006744385\n",
            "Loss in epoch 1350 is 0.3495575487613678\n",
            "Loss in epoch 1360 is 0.3477894365787506\n",
            "Loss in epoch 1370 is 0.3460400104522705\n",
            "Loss in epoch 1380 is 0.34430569410324097\n",
            "Loss in epoch 1390 is 0.34258726239204407\n",
            "Loss in epoch 1400 is 0.34089189767837524\n",
            "Loss in epoch 1410 is 0.3392091691493988\n",
            "Loss in epoch 1420 is 0.33754241466522217\n",
            "Loss in epoch 1430 is 0.33589327335357666\n",
            "Loss in epoch 1440 is 0.33426329493522644\n",
            "Loss in epoch 1450 is 0.3326459527015686\n",
            "Loss in epoch 1460 is 0.33104556798934937\n",
            "Loss in epoch 1470 is 0.32945817708969116\n",
            "Loss in epoch 1480 is 0.3278871178627014\n",
            "Loss in epoch 1490 is 0.326327383518219\n",
            "Loss in epoch 1500 is 0.3247798979282379\n",
            "Loss in epoch 1510 is 0.3232237696647644\n",
            "Loss in epoch 1520 is 0.321584016084671\n",
            "Loss in epoch 1530 is 0.31999555230140686\n",
            "Loss in epoch 1540 is 0.31821930408477783\n",
            "Loss in epoch 1550 is 0.31635674834251404\n",
            "Loss in epoch 1560 is 0.3142950236797333\n",
            "Loss in epoch 1570 is 0.31243422627449036\n",
            "Loss in epoch 1580 is 0.31069236993789673\n",
            "Loss in epoch 1590 is 0.30903536081314087\n",
            "Loss in epoch 1600 is 0.3073997497558594\n",
            "Loss in epoch 1610 is 0.3057611882686615\n",
            "Loss in epoch 1620 is 0.30414310097694397\n",
            "Loss in epoch 1630 is 0.302571177482605\n",
            "Loss in epoch 1640 is 0.3010375201702118\n",
            "Loss in epoch 1650 is 0.2994597256183624\n",
            "Loss in epoch 1660 is 0.2978595793247223\n",
            "Loss in epoch 1670 is 0.2962386906147003\n",
            "Loss in epoch 1680 is 0.2946527898311615\n",
            "Loss in epoch 1690 is 0.29311275482177734\n",
            "Loss in epoch 1700 is 0.291605144739151\n",
            "Loss in epoch 1710 is 0.29012832045555115\n",
            "Loss in epoch 1720 is 0.2886716425418854\n",
            "Loss in epoch 1730 is 0.2872393727302551\n",
            "Loss in epoch 1740 is 0.2858225107192993\n",
            "Loss in epoch 1750 is 0.28441792726516724\n",
            "Loss in epoch 1760 is 0.2830217480659485\n",
            "Loss in epoch 1770 is 0.2816409170627594\n",
            "Loss in epoch 1780 is 0.28023672103881836\n",
            "Loss in epoch 1790 is 0.2788439095020294\n",
            "Loss in epoch 1800 is 0.27747097611427307\n",
            "Loss in epoch 1810 is 0.27610859274864197\n",
            "Loss in epoch 1820 is 0.27476105093955994\n",
            "Loss in epoch 1830 is 0.2734304964542389\n",
            "Loss in epoch 1840 is 0.2721025347709656\n",
            "Loss in epoch 1850 is 0.2707301378250122\n",
            "Loss in epoch 1860 is 0.26936644315719604\n",
            "Loss in epoch 1870 is 0.2680032551288605\n",
            "Loss in epoch 1880 is 0.26665598154067993\n",
            "Loss in epoch 1890 is 0.2653229534626007\n",
            "Loss in epoch 1900 is 0.26399973034858704\n",
            "Loss in epoch 1910 is 0.26268163323402405\n",
            "Loss in epoch 1920 is 0.26137855648994446\n",
            "Loss in epoch 1930 is 0.26006796956062317\n",
            "Loss in epoch 1940 is 0.25876736640930176\n",
            "Loss in epoch 1950 is 0.25748786330223083\n",
            "Loss in epoch 1960 is 0.25621968507766724\n",
            "Loss in epoch 1970 is 0.2549605965614319\n",
            "Loss in epoch 1980 is 0.2537117898464203\n",
            "Loss in epoch 1990 is 0.2524682581424713\n",
            "Loss in epoch 2000 is 0.25119832158088684\n",
            "Loss in epoch 2010 is 0.2499229460954666\n",
            "Loss in epoch 2020 is 0.2486485242843628\n",
            "Loss in epoch 2030 is 0.2473834902048111\n",
            "Loss in epoch 2040 is 0.24611018598079681\n",
            "Loss in epoch 2050 is 0.24483367800712585\n",
            "Loss in epoch 2060 is 0.24357059597969055\n",
            "Loss in epoch 2070 is 0.24231959879398346\n",
            "Loss in epoch 2080 is 0.24103812873363495\n",
            "Loss in epoch 2090 is 0.23972705006599426\n",
            "Loss in epoch 2100 is 0.2383878380060196\n",
            "Loss in epoch 2110 is 0.2369842678308487\n",
            "Loss in epoch 2120 is 0.23548643290996552\n",
            "Loss in epoch 2130 is 0.2338305115699768\n",
            "Loss in epoch 2140 is 0.23227189481258392\n",
            "Loss in epoch 2150 is 0.23077942430973053\n",
            "Loss in epoch 2160 is 0.22934004664421082\n",
            "Loss in epoch 2170 is 0.22792749106884003\n",
            "Loss in epoch 2180 is 0.22653847932815552\n",
            "Loss in epoch 2190 is 0.22516833245754242\n",
            "Loss in epoch 2200 is 0.22380618751049042\n",
            "Loss in epoch 2210 is 0.22245819866657257\n",
            "Loss in epoch 2220 is 0.22112278640270233\n",
            "Loss in epoch 2230 is 0.2197982519865036\n",
            "Loss in epoch 2240 is 0.21845966577529907\n",
            "Loss in epoch 2250 is 0.21709460020065308\n",
            "Loss in epoch 2260 is 0.2157163769006729\n",
            "Loss in epoch 2270 is 0.21437080204486847\n",
            "Loss in epoch 2280 is 0.21304777264595032\n",
            "Loss in epoch 2290 is 0.21173930168151855\n",
            "Loss in epoch 2300 is 0.2104322910308838\n",
            "Loss in epoch 2310 is 0.20910406112670898\n",
            "Loss in epoch 2320 is 0.20779310166835785\n",
            "Loss in epoch 2330 is 0.20649266242980957\n",
            "Loss in epoch 2340 is 0.20519229769706726\n",
            "Loss in epoch 2350 is 0.2038983255624771\n",
            "Loss in epoch 2360 is 0.2026229202747345\n",
            "Loss in epoch 2370 is 0.20136776566505432\n",
            "Loss in epoch 2380 is 0.20012561976909637\n",
            "Loss in epoch 2390 is 0.19890129566192627\n",
            "Loss in epoch 2400 is 0.19767893850803375\n",
            "Loss in epoch 2410 is 0.19644129276275635\n",
            "Loss in epoch 2420 is 0.19520790874958038\n",
            "Loss in epoch 2430 is 0.19399139285087585\n",
            "Loss in epoch 2440 is 0.19277545809745789\n",
            "Loss in epoch 2450 is 0.19155248999595642\n",
            "Loss in epoch 2460 is 0.19032105803489685\n",
            "Loss in epoch 2470 is 0.18912088871002197\n",
            "Loss in epoch 2480 is 0.18795208632946014\n",
            "Loss in epoch 2490 is 0.18673650920391083\n",
            "Loss in epoch 2500 is 0.18554767966270447\n",
            "Loss in epoch 2510 is 0.1844005435705185\n",
            "Loss in epoch 2520 is 0.1832902729511261\n",
            "Loss in epoch 2530 is 0.18220214545726776\n",
            "Loss in epoch 2540 is 0.18111726641654968\n",
            "Loss in epoch 2550 is 0.18004408478736877\n",
            "Loss in epoch 2560 is 0.1789756417274475\n",
            "Loss in epoch 2570 is 0.17792537808418274\n",
            "Loss in epoch 2580 is 0.1768709421157837\n",
            "Loss in epoch 2590 is 0.17583543062210083\n",
            "Loss in epoch 2600 is 0.17480918765068054\n",
            "Loss in epoch 2610 is 0.1737917810678482\n",
            "Loss in epoch 2620 is 0.172790065407753\n",
            "Loss in epoch 2630 is 0.17181545495986938\n",
            "Loss in epoch 2640 is 0.17086414992809296\n",
            "Loss in epoch 2650 is 0.16993017494678497\n",
            "Loss in epoch 2660 is 0.1690109819173813\n",
            "Loss in epoch 2670 is 0.16810181736946106\n",
            "Loss in epoch 2680 is 0.16718639433383942\n",
            "Loss in epoch 2690 is 0.16628652811050415\n",
            "Loss in epoch 2700 is 0.16540329158306122\n",
            "Loss in epoch 2710 is 0.1645316332578659\n",
            "Loss in epoch 2720 is 0.1636757254600525\n",
            "Loss in epoch 2730 is 0.16283296048641205\n",
            "Loss in epoch 2740 is 0.1620025634765625\n",
            "Loss in epoch 2750 is 0.1611839085817337\n",
            "Loss in epoch 2760 is 0.160377636551857\n",
            "Loss in epoch 2770 is 0.1595851182937622\n",
            "Loss in epoch 2780 is 0.15880809724330902\n",
            "Loss in epoch 2790 is 0.15804427862167358\n",
            "Loss in epoch 2800 is 0.15729090571403503\n",
            "Loss in epoch 2810 is 0.15655545890331268\n",
            "Loss in epoch 2820 is 0.15582877397537231\n",
            "Loss in epoch 2830 is 0.15510793030261993\n",
            "Loss in epoch 2840 is 0.1543949991464615\n",
            "Loss in epoch 2850 is 0.1536799967288971\n",
            "Loss in epoch 2860 is 0.15297146141529083\n",
            "Loss in epoch 2870 is 0.15226131677627563\n",
            "Loss in epoch 2880 is 0.1515672355890274\n",
            "Loss in epoch 2890 is 0.1508859097957611\n",
            "Loss in epoch 2900 is 0.1502188742160797\n",
            "Loss in epoch 2910 is 0.1495625078678131\n",
            "Loss in epoch 2920 is 0.14890660345554352\n",
            "Loss in epoch 2930 is 0.14823761582374573\n",
            "Loss in epoch 2940 is 0.14758874475955963\n",
            "Loss in epoch 2950 is 0.14695096015930176\n",
            "Loss in epoch 2960 is 0.14632567763328552\n",
            "Loss in epoch 2970 is 0.14570863544940948\n",
            "Loss in epoch 2980 is 0.14510227739810944\n",
            "Loss in epoch 2990 is 0.14450417459011078\n",
            "Loss in epoch 3000 is 0.1439153403043747\n",
            "Loss in epoch 3010 is 0.14333757758140564\n",
            "Loss in epoch 3020 is 0.1427658647298813\n",
            "Loss in epoch 3030 is 0.14219863712787628\n",
            "Loss in epoch 3040 is 0.14164088666439056\n",
            "Loss in epoch 3050 is 0.14109355211257935\n",
            "Loss in epoch 3060 is 0.14055539667606354\n",
            "Loss in epoch 3070 is 0.1400025188922882\n",
            "Loss in epoch 3080 is 0.13945885002613068\n",
            "Loss in epoch 3090 is 0.13892191648483276\n",
            "Loss in epoch 3100 is 0.13839353621006012\n",
            "Loss in epoch 3110 is 0.13787688314914703\n",
            "Loss in epoch 3120 is 0.13736747205257416\n",
            "Loss in epoch 3130 is 0.13686078786849976\n",
            "Loss in epoch 3140 is 0.13636215031147003\n",
            "Loss in epoch 3150 is 0.13586902618408203\n",
            "Loss in epoch 3160 is 0.13538207113742828\n",
            "Loss in epoch 3170 is 0.13490155339241028\n",
            "Loss in epoch 3180 is 0.1344287395477295\n",
            "Loss in epoch 3190 is 0.13395749032497406\n",
            "Loss in epoch 3200 is 0.13348689675331116\n",
            "Loss in epoch 3210 is 0.13302499055862427\n",
            "Loss in epoch 3220 is 0.13257069885730743\n",
            "Loss in epoch 3230 is 0.1321212649345398\n",
            "Loss in epoch 3240 is 0.13167284429073334\n",
            "Loss in epoch 3250 is 0.1312193125486374\n",
            "Loss in epoch 3260 is 0.13076984882354736\n",
            "Loss in epoch 3270 is 0.13032835721969604\n",
            "Loss in epoch 3280 is 0.12988778948783875\n",
            "Loss in epoch 3290 is 0.12945422530174255\n",
            "Loss in epoch 3300 is 0.1290256381034851\n",
            "Loss in epoch 3310 is 0.12860167026519775\n",
            "Loss in epoch 3320 is 0.1281839907169342\n",
            "Loss in epoch 3330 is 0.1277705729007721\n",
            "Loss in epoch 3340 is 0.12736055254936218\n",
            "Loss in epoch 3350 is 0.12695488333702087\n",
            "Loss in epoch 3360 is 0.12655216455459595\n",
            "Loss in epoch 3370 is 0.12615172564983368\n",
            "Loss in epoch 3380 is 0.12575478851795197\n",
            "Loss in epoch 3390 is 0.125361829996109\n",
            "Loss in epoch 3400 is 0.1249716579914093\n",
            "Loss in epoch 3410 is 0.12458579242229462\n",
            "Loss in epoch 3420 is 0.1242055892944336\n",
            "Loss in epoch 3430 is 0.12382474541664124\n",
            "Loss in epoch 3440 is 0.1234515979886055\n",
            "Loss in epoch 3450 is 0.12307965755462646\n",
            "Loss in epoch 3460 is 0.12270946055650711\n",
            "Loss in epoch 3470 is 0.12234462797641754\n",
            "Loss in epoch 3480 is 0.12197915464639664\n",
            "Loss in epoch 3490 is 0.1216115951538086\n",
            "Loss in epoch 3500 is 0.121248759329319\n",
            "Loss in epoch 3510 is 0.12089145928621292\n",
            "Loss in epoch 3520 is 0.12053541094064713\n",
            "Loss in epoch 3530 is 0.12018106132745743\n",
            "Loss in epoch 3540 is 0.11983335763216019\n",
            "Loss in epoch 3550 is 0.11948621273040771\n",
            "Loss in epoch 3560 is 0.11914577335119247\n",
            "Loss in epoch 3570 is 0.1188034787774086\n",
            "Loss in epoch 3580 is 0.11846773326396942\n",
            "Loss in epoch 3590 is 0.11813366413116455\n",
            "Loss in epoch 3600 is 0.11780022084712982\n",
            "Loss in epoch 3610 is 0.11747010797262192\n",
            "Loss in epoch 3620 is 0.11714345216751099\n",
            "Loss in epoch 3630 is 0.11681996285915375\n",
            "Loss in epoch 3640 is 0.116499163210392\n",
            "Loss in epoch 3650 is 0.11618079990148544\n",
            "Loss in epoch 3660 is 0.11586473882198334\n",
            "Loss in epoch 3670 is 0.11555145680904388\n",
            "Loss in epoch 3680 is 0.11524026840925217\n",
            "Loss in epoch 3690 is 0.11493131518363953\n",
            "Loss in epoch 3700 is 0.11462423950433731\n",
            "Loss in epoch 3710 is 0.11431904882192612\n",
            "Loss in epoch 3720 is 0.11401644349098206\n",
            "Loss in epoch 3730 is 0.11371441930532455\n",
            "Loss in epoch 3740 is 0.11341630667448044\n",
            "Loss in epoch 3750 is 0.11311864107847214\n",
            "Loss in epoch 3760 is 0.11282531172037125\n",
            "Loss in epoch 3770 is 0.11253136396408081\n",
            "Loss in epoch 3780 is 0.11224308609962463\n",
            "Loss in epoch 3790 is 0.11195235699415207\n",
            "Loss in epoch 3800 is 0.11166609823703766\n",
            "Loss in epoch 3810 is 0.11138328909873962\n",
            "Loss in epoch 3820 is 0.11110111325979233\n",
            "Loss in epoch 3830 is 0.11081817001104355\n",
            "Loss in epoch 3840 is 0.11053979396820068\n",
            "Loss in epoch 3850 is 0.11026173084974289\n",
            "Loss in epoch 3860 is 0.10998735576868057\n",
            "Loss in epoch 3870 is 0.10971356183290482\n",
            "Loss in epoch 3880 is 0.10943925380706787\n",
            "Loss in epoch 3890 is 0.10916858911514282\n",
            "Loss in epoch 3900 is 0.10890170186758041\n",
            "Loss in epoch 3910 is 0.10863719135522842\n",
            "Loss in epoch 3920 is 0.10837201774120331\n",
            "Loss in epoch 3930 is 0.10811036825180054\n",
            "Loss in epoch 3940 is 0.10785151273012161\n",
            "Loss in epoch 3950 is 0.10759321600198746\n",
            "Loss in epoch 3960 is 0.10733526945114136\n",
            "Loss in epoch 3970 is 0.10707863420248032\n",
            "Loss in epoch 3980 is 0.10682474076747894\n",
            "Loss in epoch 3990 is 0.10656964778900146\n",
            "Loss in epoch 4000 is 0.10631624609231949\n",
            "Loss in epoch 4010 is 0.10606595873832703\n",
            "Loss in epoch 4020 is 0.105814129114151\n",
            "Loss in epoch 4030 is 0.10556352883577347\n",
            "Loss in epoch 4040 is 0.10531563311815262\n",
            "Loss in epoch 4050 is 0.10506629943847656\n",
            "Loss in epoch 4060 is 0.10482051968574524\n",
            "Loss in epoch 4070 is 0.10457661747932434\n",
            "Loss in epoch 4080 is 0.10433288663625717\n",
            "Loss in epoch 4090 is 0.10409136116504669\n",
            "Loss in epoch 4100 is 0.10384762287139893\n",
            "Loss in epoch 4110 is 0.10360663384199142\n",
            "Loss in epoch 4120 is 0.10336793214082718\n",
            "Loss in epoch 4130 is 0.10313137620687485\n",
            "Loss in epoch 4140 is 0.10289671272039413\n",
            "Loss in epoch 4150 is 0.10266175121068954\n",
            "Loss in epoch 4160 is 0.10242873430252075\n",
            "Loss in epoch 4170 is 0.10219720005989075\n",
            "Loss in epoch 4180 is 0.10196676850318909\n",
            "Loss in epoch 4190 is 0.1017373651266098\n",
            "Loss in epoch 4200 is 0.10151372849941254\n",
            "Loss in epoch 4210 is 0.10128746926784515\n",
            "Loss in epoch 4220 is 0.10104010254144669\n",
            "Loss in epoch 4230 is 0.10079523175954819\n",
            "Loss in epoch 4240 is 0.10056011378765106\n",
            "Loss in epoch 4250 is 0.10030731558799744\n",
            "Loss in epoch 4260 is 0.10005824267864227\n",
            "Loss in epoch 4270 is 0.09980826079845428\n",
            "Loss in epoch 4280 is 0.09956351667642593\n",
            "Loss in epoch 4290 is 0.09932425618171692\n",
            "Loss in epoch 4300 is 0.09908398985862732\n",
            "Loss in epoch 4310 is 0.0988432839512825\n",
            "Loss in epoch 4320 is 0.09860790520906448\n",
            "Loss in epoch 4330 is 0.09837840497493744\n",
            "Loss in epoch 4340 is 0.09815055131912231\n",
            "Loss in epoch 4350 is 0.09791983664035797\n",
            "Loss in epoch 4360 is 0.0976971983909607\n",
            "Loss in epoch 4370 is 0.09747029095888138\n",
            "Loss in epoch 4380 is 0.09723526984453201\n",
            "Loss in epoch 4390 is 0.09698926657438278\n",
            "Loss in epoch 4400 is 0.09675124287605286\n",
            "Loss in epoch 4410 is 0.09651686251163483\n",
            "Loss in epoch 4420 is 0.09628842771053314\n",
            "Loss in epoch 4430 is 0.09605976939201355\n",
            "Loss in epoch 4440 is 0.09583140909671783\n",
            "Loss in epoch 4450 is 0.09559523314237595\n",
            "Loss in epoch 4460 is 0.09536318480968475\n",
            "Loss in epoch 4470 is 0.0951363816857338\n",
            "Loss in epoch 4480 is 0.09491102397441864\n",
            "Loss in epoch 4490 is 0.09463246166706085\n",
            "Loss in epoch 4500 is 0.09436099976301193\n",
            "Loss in epoch 4510 is 0.0940965786576271\n",
            "Loss in epoch 4520 is 0.09384015202522278\n",
            "Loss in epoch 4530 is 0.09358378499746323\n",
            "Loss in epoch 4540 is 0.09333816915750504\n",
            "Loss in epoch 4550 is 0.0930945947766304\n",
            "Loss in epoch 4560 is 0.09284992516040802\n",
            "Loss in epoch 4570 is 0.09259981662034988\n",
            "Loss in epoch 4580 is 0.09234990924596786\n",
            "Loss in epoch 4590 is 0.09211286157369614\n",
            "Loss in epoch 4600 is 0.09188300371170044\n",
            "Loss in epoch 4610 is 0.09164948761463165\n",
            "Loss in epoch 4620 is 0.09142479300498962\n",
            "Loss in epoch 4630 is 0.09119908511638641\n",
            "Loss in epoch 4640 is 0.09097431600093842\n",
            "Loss in epoch 4650 is 0.09074845910072327\n",
            "Loss in epoch 4660 is 0.09052880108356476\n",
            "Loss in epoch 4670 is 0.09030842781066895\n",
            "Loss in epoch 4680 is 0.09009258449077606\n",
            "Loss in epoch 4690 is 0.08987785875797272\n",
            "Loss in epoch 4700 is 0.08966795355081558\n",
            "Loss in epoch 4710 is 0.08945723623037338\n",
            "Loss in epoch 4720 is 0.08924589306116104\n",
            "Loss in epoch 4730 is 0.08903546631336212\n",
            "Loss in epoch 4740 is 0.08882709592580795\n",
            "Loss in epoch 4750 is 0.08862510323524475\n",
            "Loss in epoch 4760 is 0.08841598778963089\n",
            "Loss in epoch 4770 is 0.08821380138397217\n",
            "Loss in epoch 4780 is 0.08801688253879547\n",
            "Loss in epoch 4790 is 0.0878128856420517\n",
            "Loss in epoch 4800 is 0.08761785179376602\n",
            "Loss in epoch 4810 is 0.0874156728386879\n",
            "Loss in epoch 4820 is 0.08722048252820969\n",
            "Loss in epoch 4830 is 0.08702933043241501\n",
            "Loss in epoch 4840 is 0.08683079481124878\n",
            "Loss in epoch 4850 is 0.08664458245038986\n",
            "Loss in epoch 4860 is 0.08643937855958939\n",
            "Loss in epoch 4870 is 0.08624245226383209\n",
            "Loss in epoch 4880 is 0.08604472875595093\n",
            "Loss in epoch 4890 is 0.08585763722658157\n",
            "Loss in epoch 4900 is 0.08566543459892273\n",
            "Loss in epoch 4910 is 0.08547051250934601\n",
            "Loss in epoch 4920 is 0.08528271317481995\n",
            "Loss in epoch 4930 is 0.0850953534245491\n",
            "Loss in epoch 4940 is 0.08491096645593643\n",
            "Loss in epoch 4950 is 0.08472727239131927\n",
            "Loss in epoch 4960 is 0.08454686403274536\n",
            "Loss in epoch 4970 is 0.0843636766076088\n",
            "Loss in epoch 4980 is 0.08418388664722443\n",
            "Loss in epoch 4990 is 0.08400915563106537\n",
            "Done training \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "fMPxG1i873W7",
        "outputId": "8ed83937-f40a-4e0e-a259-e409fff8fc9e"
      },
      "source": [
        "  fig = plt.figure()\n",
        "  plt.plot(range(0, no_epochs), train_losses, color='blue')\n",
        "  plt.legend(['Train Loss'], loc='upper right')\n",
        "  plt.xlabel('number of epochs')\n",
        "  plt.ylabel('loss')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN8btFSP3yU2"
      },
      "source": [
        "### 4. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsmVfo49Kytp",
        "outputId": "73bdda50-20d6-41e3-bb45-ce40c114f6fc"
      },
      "source": [
        "net.eval() # set network to evaluation mode\n",
        "y_pred = net(test_x)\n",
        "_, predicted = torch.max(y_pred.data, 1)\n",
        "correct = (predicted == test_y).sum().item()\n",
        "print(f\"Accuarcy is {100. * correct / len(test_x)}%\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuarcy is 90.83333333333333%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB9CFaSTWsNG"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}
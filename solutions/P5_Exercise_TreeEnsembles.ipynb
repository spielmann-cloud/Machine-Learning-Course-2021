{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung: Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook werden wir verschiedene Formen des \"Ensemble Learning\" einsetzen und einen einfachen Bagging-Algorithmus selbst implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorab initialisieren wir die Zufallsgeneratoren um vergleichbare Ergebnisse zu erhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für diese Übung verwenden wir den [Wein-Datensatz](https://archive.ics.uci.edu/ml/datasets/wine), welcher ebenfalls ein bekannter Datensatz in der ML-Welt ist.\n",
    "Die offizielle Beschreibung lautet:\n",
    "```\n",
    "These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines.\n",
    "```\n",
    "Anhand dieser Merkmale soll die Qualität (Spalte `quality`) des Weins vorhergesagt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/wine.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir loslegen, schauen wir uns die Verteilung des Labels an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['quality'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Decision Tree, Random Forest, GBT\n",
    "Trainieren Sie die folgenden Modelle und ermitteln Sie die Accuarcy auf den Testdaten. Geben Sie dabei jeweils den Parameter `random_state=0` bei der Erstellung des Modells and und beschränken Sie die maximale Baumtiefe auf `max_depth=3`.\n",
    "- Einfacher Entscheidungsbaum (`DecisionTreeClassifier`)\n",
    "- Random Forest (`RandomForestClassifier`)\n",
    "- GBT (`GradientBoostingClassifier`)\n",
    "\n",
    "Hinweis: Für diese Modelle müssen wir die Daten nicht skalieren und kein One-hot-encoding durchführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clfTre = DecisionTreeClassifier(criterion=\"entropy\", random_state=0, max_depth=3)\n",
    "clfTre.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.575"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = clfTre.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.659375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0, max_depth=3)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(random_state=0, max_depth=3)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2: GBT Tuning\n",
    "Das `GradientBoostingClassifier`-Modell hat als wichtigste Hyperparameter die Anzahl der Bäume die trainiert werden (`n_estimators`) und die maximale Baumtiefe (`max_depth`). Hinweis: Weitere Parameter findet man in der [Dokumentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html).\n",
    "\n",
    "1. Führen Sie eine Cross-Validierung für diese Hyperparameter über die folgenden Werte durch:\n",
    "    - `n_estimators` $\\in [60, 80, 100, 120, 140]$ und\n",
    "    - `max_depth` $\\in [2, 3, 4, 5]$.\n",
    "\n",
    "Nehmen Sie [dieses Code-Beispiel](https://chrisalbon.com/machine_learning/model_evaluation/cross_validation_parameter_tuning_grid_search/) als Vorlage. Hinweis: Der `import`-Befehl für `GridSearchCV` ist im Beispiel out-dated und lautet richtig: `from sklearn.model_selection import GridSearchCV`.\n",
    "2. Welches sind die besten Werte für `n_estimators` und `max_depth`?\n",
    "3. Trainieren Sie einen neuen GBT mit diesen Parametern und machen Sie eine Vorhersage auf den Testdaten. Vergleichen Sie die Ergebnisse mit Aufgabe 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3: Bagging-Modell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie ein Bagging-Modell von Hand (d.h. nicht die Sklearn-Library verwenden) und testen Sie es auf den Testdaten. Das Bagging-Modell soll folgende Eigenschaften haben:\n",
    "- Das Modell soll 10 Basismodelle haben, welche einfache `DecisionTreeClassifier` sind.\n",
    "- Jeder dieser DecisionTrees soll auf 70% der Trainingsdaten trainiert werden (Sampling mit Zurücklegen). Tipp: Nutzen Sie `X_train.sample(...)`.\n",
    "- Bei der Vorhersage soll die am häufigsten vorhergesagte Klasse als Gesamtvorhersage dienen.\n",
    "- Testen Sie das Modell auf den Testdaten."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
